"""
ETFæŒ‡æ•°æ—¥çº¿æ•°æ®ç®¡ç†ç±»
- ä½¿ç”¨Tushare index_dailyæ¥å£ï¼ŒæŒ‰äº¤æ˜“æ—¥å¾ªç¯ï¼ˆå®˜æ–¹æ¨èæ–¹å¼ï¼‰è·å–æ•°æ®
- æ”¯æŒæŒ‰å¼€å§‹/ç»“æŸæ—¥æœŸè·å–å¤šä¸ªæŒ‡æ•°åœ¨åŒºé—´å†…çš„æ‰€æœ‰äº¤æ˜“æ—¥æ•°æ®
- æ¯50æ¡æ•°æ®æ‰¹é‡ä¿å­˜ä¸€æ¬¡åˆ°MySQLï¼Œé™ä½ç»ˆç«¯ä¸­æ–­å¯¼è‡´çš„æ•°æ®ä¸¢å¤±é£é™©

æ³¨æ„ï¼šindex_dailyæ¥å£éœ€è¦ä¼ å…¥å…·ä½“æŒ‡æ•°ä»£ç (ts_code)ï¼Œè‹¥æœªæä¾›æŒ‡æ•°ä»£ç åˆ—è¡¨ï¼Œå°†å°è¯•é€šè¿‡index_basicè·å–å…¨éƒ¨æŒ‡æ•°åˆ—è¡¨ã€‚
"""
import os
import sys
from typing import List, Optional, Tuple, Dict, Any

import pandas as pd
import tushare

# æ·»åŠ å¿…è¦çš„è·¯å¾„åˆ°sys.path
current_dir = os.path.dirname(os.path.abspath(__file__))
core_dir = os.path.dirname(current_dir)  # /Users/gelin/Desktop/store/dev/python/20250926stock/StockIBelive/IBelive/core
if core_dir not in sys.path:
    sys.path.insert(0, core_dir)

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°sys.path
project_root = os.path.dirname(os.path.dirname(core_dir))  # /Users/gelin/Desktop/store/dev/python/20250926stock/StockIBelive
if project_root not in sys.path:
    sys.path.insert(0, project_root)


# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥æ‰€æœ‰æ¨¡å—
from mysql_manager import MySQLManager
from models.etf_index_daily import ETFIndexDaily
from parse_config import ParseConfig
import tushare


class ETFIndexDailyManager:
    """ETFæŒ‡æ•°æ—¥çº¿æ•°æ®ç®¡ç†ç±»"""

    DEFAULT_FIELDS = ETFIndexDaily.DEFAULT_FIELDS

    def __init__(self, config, pro: tushare.pro):
        """
        :param config: é…ç½®å¯¹è±¡ï¼Œéœ€æä¾›get_data_dir()å’Œget_token()/get_mysql_config()
        :param pro: Tushare Proæ¥å£å¯¹è±¡
        """
        self.config = config
        self.pro = pro
        self.data_dir = config.get_data_dir()
        self.mysql_manager = MySQLManager(config)

    def _dataframe_to_etf_index_daily_objects(self, df: pd.DataFrame) -> List[ETFIndexDaily]:
        """å°†DataFrameè½¬æ¢ä¸ºETFIndexDailyå¯¹è±¡åˆ—è¡¨"""
        etf_objects = []
        for _, row in df.iterrows():
            # å°†è¡Œæ•°æ®è½¬æ¢ä¸ºå­—å…¸
            row_dict = row.to_dict()
            # ä½¿ç”¨æ¨¡å‹çš„from_dictæ–¹æ³•åˆ›å»ºå¯¹è±¡
            etf_obj = ETFIndexDaily.from_dict(row_dict)
            etf_objects.append(etf_obj)
        return etf_objects

    def _save_etf_index_daily_objects_to_mysql(self, etf_objects: List[ETFIndexDaily], table_name: str = 'etf_index_daily') -> bool:
        """ä¿å­˜ETFIndexDailyå¯¹è±¡åˆ—è¡¨åˆ°MySQL"""
        if not etf_objects:
            return False
        
        # å°†å¯¹è±¡åˆ—è¡¨è½¬æ¢ä¸ºDataFrame
        data_dicts = []
        for obj in etf_objects:
            obj_dict = {
                'ts_code': obj.ts_code,
                'trade_date': obj.trade_date,
                'open': obj.open,
                'high': obj.high,
                'low': obj.low,
                'close': obj.close,
                'pre_close': obj.pre_close,
                'change': obj.change,
                'pct_chg': obj.pct_chg,
                'vol': obj.vol,
                'amount': obj.amount,
                'data_status': 'æ­£å¸¸',
                'status_reason': ''
            }
            data_dicts.append(obj_dict)
        
        df = pd.DataFrame(data_dicts)
        return self._save_index_daily_to_mysql(df, table_name)

    def _preprocess_index_daily(self, df: pd.DataFrame) -> pd.DataFrame:
        """é¢„å¤„ç†index_dailyæ•°æ®"""
        if 'trade_date' in df.columns:
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d').dt.date
        for field in ['open', 'high', 'low', 'close', 'pre_close', 'change', 'pct_chg', 'vol', 'amount']:
            if field in df.columns:
                df[field] = pd.to_numeric(df[field], errors='coerce').fillna(0.0)
                df[field] = df[field].replace([float('inf'), float('-inf')], 0.0)
        return df

    def _get_index_daily_table_queries(self, table_name: str, include_status_fields: bool = True) -> Tuple[str, str, List[str], Dict[str, Any]]:
        """æ„å»ºè¡¨åˆ›å»ºä¸æ’å…¥SQL"""
        status_fields_sql = ""
        if include_status_fields:
            status_fields_sql = """
            data_status VARCHAR(10),
            status_reason VARCHAR(100),
            """
        create_table_query = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            id INT AUTO_INCREMENT PRIMARY KEY,
            ts_code VARCHAR(20),
            trade_date DATETIME,
            close FLOAT,
            open FLOAT,
            high FLOAT,
            low FLOAT,
            pre_close FLOAT,
            `change` FLOAT,
            pct_chg FLOAT,
            vol FLOAT,
            amount FLOAT,
            {status_fields_sql}
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
            UNIQUE KEY unique_index_date (ts_code, trade_date)
        )
        """
        status_fields_insert = status_fields_values = status_fields_update = ""
        if include_status_fields:
            status_fields_insert = "data_status, status_reason,"
            status_fields_values = "%s, %s,"
            status_fields_update = """
            data_status = VALUES(data_status),
            status_reason = VALUES(status_reason),
            """
        insert_query = f"""
        INSERT INTO {table_name} (ts_code, trade_date, close, open, high, low, pre_close,
                                  `change`, pct_chg, vol, amount, {status_fields_insert}
                                  created_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, {status_fields_values} CURRENT_TIMESTAMP)
        ON DUPLICATE KEY UPDATE
            close = VALUES(close),
            open = VALUES(open),
            high = VALUES(high),
            low = VALUES(low),
            pre_close = VALUES(pre_close),
            `change` = VALUES(`change`),
            pct_chg = VALUES(pct_chg),
            vol = VALUES(vol),
            amount = VALUES(amount),
            {status_fields_update}
            updated_at = CURRENT_TIMESTAMP
        """
        expected_columns = self.DEFAULT_FIELDS.copy()
        fill_missing_defaults = {
            'close': 0.0, 'open': 0.0, 'high': 0.0, 'low': 0.0,
            'pre_close': 0.0, 'change': 0.0, 'pct_chg': 0.0, 'vol': 0.0, 'amount': 0.0,
            'data_status': '', 'status_reason': ''
        }
        if include_status_fields:
            expected_columns.extend(['data_status', 'status_reason'])
        return create_table_query, insert_query, expected_columns, fill_missing_defaults

    def get_all_index_codes(self) -> List[str]:
        """å°è¯•é€šè¿‡index_basicè·å–å…¨éƒ¨æŒ‡æ•°ts_codeåˆ—è¡¨"""
        try:
            df = self.pro.index_basic()  # è·å–æ‰€æœ‰æŒ‡æ•°åŸºç¡€ä¿¡æ¯
            if df is not None and not df.empty and 'ts_code' in df.columns:
                return df['ts_code'].dropna().unique().tolist()
        except Exception as e:
            print(f"âš ï¸ è·å–æŒ‡æ•°åˆ—è¡¨å¤±è´¥: {e}")
        return []

    def fetch_index_daily_by_trade_date(self, trade_date: str, index_codes: Optional[List[str]] = None) -> pd.DataFrame:
        """
        è·å–æŒ‡å®šäº¤æ˜“æ—¥çš„æŒ‡æ•°æ—¥çº¿æ•°æ®ï¼ˆæŒ‰æŒ‡æ•°ä»£ç å¾ªç¯ï¼‰
        :param trade_date: äº¤æ˜“æ—¥ YYYYMMDD
        :param index_codes: æŒ‡æ•°ä»£ç åˆ—è¡¨ï¼Œè‹¥ä¸ºç©ºåˆ™å°è¯•è·å–å…¨éƒ¨æŒ‡æ•°
        """
        if not index_codes:
            index_codes = self.get_all_index_codes()
            if not index_codes:
                print(f"âš ï¸ æœªæä¾›æŒ‡æ•°ä»£ç ä¸”æ— æ³•è‡ªåŠ¨è·å–æŒ‡æ•°åˆ—è¡¨ï¼Œtrade_date={trade_date}")
                return pd.DataFrame()
        all_rows: List[pd.DataFrame] = []
        for code in index_codes:
            try:
                df = self.pro.index_daily(ts_code=code, trade_date=trade_date)
                if df is not None and not df.empty:
                    df = self._preprocess_index_daily(df)
                    df['data_status'] = 'æ­£å¸¸'
                    df['status_reason'] = ''
                    all_rows.append(df)
                else:
                    # ç”Ÿæˆå ä½è¡Œï¼ˆæ— æ•°æ®ï¼‰
                    empty = pd.DataFrame([{**{k: None for k in self.DEFAULT_FIELDS}, 'ts_code': code, 'trade_date': trade_date}])
                    empty = self._preprocess_index_daily(empty)
                    empty['data_status'] = 'åœç›˜'
                    empty['status_reason'] = 'å½“æ—¥æ— è¯¥æŒ‡æ•°æ•°æ®'
                    all_rows.append(empty)
            except Exception as e:
                print(f"âŒ æŒ‡æ•° {code} åœ¨ {trade_date} è·å–å¤±è´¥: {e}")
                error = pd.DataFrame([{**{k: None for k in self.DEFAULT_FIELDS}, 'ts_code': code, 'trade_date': trade_date}])
                error = self._preprocess_index_daily(error)
                error['data_status'] = 'é”™è¯¯'
                error['status_reason'] = f'æ•°æ®è·å–å¤±è´¥: {str(e)}'
                all_rows.append(error)
        if all_rows:
            return pd.concat(all_rows, ignore_index=True)
        return pd.DataFrame()

    def _save_index_daily_to_mysql(self, df: pd.DataFrame, table_name: str = 'etf_index_daily') -> bool:
        """ä¿å­˜æŒ‡æ•°æ•°æ®åˆ°MySQL"""
        if df is None or df.empty:
            return False
        create_table_query, insert_query, expected_columns, fill_missing_defaults = self._get_index_daily_table_queries(table_name, include_status_fields=True)
        table_created = self.mysql_manager.create_table_if_not_exists(table_name, create_table_query)
        if not table_created:
            print(f"âŒ åˆ›å»ºè¡¨ {table_name} å¤±è´¥")
            return False
        # ç¡®ä¿trade_dateä¸ºdatetime
        df['trade_date'] = df['trade_date'].apply(lambda x: pd.to_datetime(x) if not pd.api.types.is_datetime64_any_dtype(x) else x)
        return self.mysql_manager.save_dataframe_to_table(
            df=df,
            table_name=table_name,
            insert_query=insert_query,
            expected_columns=expected_columns,
            fill_missing_defaults=fill_missing_defaults
        )

    def fetch_and_save_index_daily_by_trade_date(self, trade_date: str, index_codes: Optional[List[str]] = None, batch_size: int = 50) -> pd.DataFrame:
        """è·å–å¹¶æŒ‰æ‰¹æ¬¡ä¿å­˜æŒ‡å®šäº¤æ˜“æ—¥çš„æŒ‡æ•°æ•°æ®"""
        df = self.fetch_index_daily_by_trade_date(trade_date, index_codes)
        if df.empty:
            print(f"âš ï¸ {trade_date} æ— å¯ä¿å­˜æŒ‡æ•°æ•°æ®")
            return df
        # æ‰¹å¤„ç†ä¿å­˜
        total = len(df)
        saved_total = 0
        for i in range(0, total, batch_size):
            batch_df = df.iloc[i:i + batch_size]
            ok = self._save_index_daily_to_mysql(batch_df)
            if ok:
                saved_total += len(batch_df)
                print(f"âœ… {trade_date} æ‰¹é‡ä¿å­˜ {len(batch_df)}/{total}ï¼Œç´¯è®¡ä¿å­˜ {saved_total}")
            else:
                print(f"âš ï¸ {trade_date} æ‰¹é‡ä¿å­˜å¤±è´¥ï¼šåŒºé—´ {i}-{i + len(batch_df)}")
        return df

    def fetch_and_save_index_daily_period(self, start_date: str, end_date: str, index_codes: Optional[List[str]] = None, batch_size: int = 50) -> pd.DataFrame:
        """
        è·å–å¹¶ä¿å­˜åŒºé—´å†…æ‰€æœ‰äº¤æ˜“æ—¥çš„æŒ‡æ•°æ—¥çº¿æ•°æ®ï¼š
        - æŒ‰äº¤æ˜“æ—¥å¾ªç¯ï¼ˆå®˜æ–¹æ¨èï¼‰
        - æ¯50æ¡æ•°æ®ä¿å­˜ä¸€æ¬¡
        - æ”¯æŒæŒ‡å®šæŒ‡æ•°åˆ—è¡¨ï¼ŒæœªæŒ‡å®šæ—¶å°è¯•è‡ªåŠ¨è·å–å…¨éƒ¨æŒ‡æ•°
        """
        try:
            trade_cal = self.pro.trade_cal(exchange='', start_date=start_date, end_date=end_date, fields=['cal_date', 'is_open'])
            if trade_cal.empty:
                print(f"âš ï¸ æœªæ‰¾åˆ° {start_date}-{end_date} çš„äº¤æ˜“æ—¥å†")
                return pd.DataFrame()
            trading_days = trade_cal[trade_cal['is_open'] == 1]['cal_date'].tolist()
            if not trading_days:
                print(f"âš ï¸ åŒºé—´ {start_date}-{end_date} æ— äº¤æ˜“æ—¥")
                return pd.DataFrame()
            print(f"ğŸ“… åŒºé—´äº¤æ˜“æ—¥æ•°é‡: {len(trading_days)} ä» {start_date} åˆ° {end_date}")
            buffer: List[pd.DataFrame] = []
            saved_total = 0
            all_data: List[pd.DataFrame] = []
            for trade_date in trading_days:
                daily_df = self.fetch_index_daily_by_trade_date(trade_date, index_codes)
                if daily_df is not None and not daily_df.empty:
                    buffer.append(daily_df)
                    all_data.append(daily_df)
                    # å¤Ÿæ‰¹æ¬¡åˆ™ä¿å­˜
                    curr_count = sum(len(x) for x in buffer)
                    if curr_count >= batch_size:
                        to_save = pd.concat(buffer, ignore_index=True)
                        ok = self._save_index_daily_to_mysql(to_save)
                        if ok:
                            saved_total += len(to_save)
                            print(f"âœ… ç´¯è®¡ä¿å­˜ {saved_total} æ¡è®°å½•")
                        else:
                            print("âš ï¸ æ‰¹é‡ä¿å­˜å¤±è´¥ï¼ˆperiodï¼‰")
                        buffer.clear()
                else:
                    print(f"âš ï¸ {trade_date} æ— æŒ‡æ•°æ•°æ®")
            # ä¿å­˜å‰©ä½™ç¼“å†²
            if buffer:
                to_save = pd.concat(buffer, ignore_index=True)
                ok = self._save_index_daily_to_mysql(to_save)
                if ok:
                    saved_total += len(to_save)
                    print(f"âœ… åŒºé—´æ”¶å°¾ä¿å­˜ {len(to_save)} æ¡ï¼Œç´¯è®¡ä¿å­˜ {saved_total}")
                else:
                    print("âš ï¸ æ”¶å°¾æ‰¹é‡ä¿å­˜å¤±è´¥")
            if all_data:
                return pd.concat(all_data, ignore_index=True)
            return pd.DataFrame()
        except Exception as e:
            print(f"âŒ åŒºé—´è·å–ä¿å­˜å¤±è´¥: {e}")
            return pd.DataFrame()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        print("ğŸš€ å¼€å§‹æµ‹è¯•ETFæŒ‡æ•°æ—¥çº¿æ•°æ®ç®¡ç†å™¨...")
        
        # åˆå§‹åŒ–é…ç½®å’ŒTushare
        config = ParseConfig()
        pro = tushare.pro_api(config.get_token())
        
        # åˆ›å»ºç®¡ç†å™¨å®ä¾‹
        manager = ETFIndexDailyManager(config, pro)
        
        print("âœ… ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•è·å–æŒ‡æ•°ä»£ç åˆ—è¡¨
        index_codes = manager.get_all_index_codes()
        print(f"ğŸ“Š è·å–åˆ° {len(index_codes)} ä¸ªæŒ‡æ•°ä»£ç ")
        if index_codes:
            print(f"ğŸ“‹ å‰5ä¸ªæŒ‡æ•°ä»£ç : {index_codes[:5]}")
        
        # æµ‹è¯•è·å–å•æ—¥æ•°æ®ï¼ˆä½¿ç”¨å°‘é‡æŒ‡æ•°ä»£ç è¿›è¡Œæµ‹è¯•ï¼‰
        # test_codes = index_codes[:3] if index_codes else ['000001.SH', '399001.SZ']
        test_codes = ['510300.SH', '159949.SZ','588000.SH','513180.SH']
        print(f"ğŸ§ª æµ‹è¯•æŒ‡æ•°ä»£ç : {test_codes}")
        
        # # è·å–æµ‹è¯•æ—¥æœŸçš„æ•°æ®
        # test_date = '20250927'
        # df = manager.fetch_index_daily_by_trade_date(test_date, test_codes)
        
        # if not df.empty:
        #     print(f"âœ… æˆåŠŸè·å– {test_date} çš„æŒ‡æ•°æ•°æ®")
        #     print(f"ğŸ“ˆ æ•°æ®å½¢çŠ¶: {df.shape}")
        #     print(f"ğŸ“Š æ•°æ®é¢„è§ˆ:")
        #     print(df.head())
            
        #     # æµ‹è¯•ä¿å­˜åˆ°MySQL
        #     success = manager._save_index_daily_to_mysql(df)
        #     if success:
        #         print("âœ… æ•°æ®æˆåŠŸä¿å­˜åˆ°MySQL")
        #     else:
        #         print("âš ï¸  æ•°æ®ä¿å­˜åˆ°MySQLå¤±è´¥")
        # else:
        #     print(f"âš ï¸  æœªè·å–åˆ° {test_date} çš„æŒ‡æ•°æ•°æ®")
            
        # æµ‹è¯•åŒºé—´æ•°æ®è·å–
        print("\nğŸ§ª æµ‹è¯•åŒºé—´æ•°æ®è·å–...")
        result_df = manager.fetch_and_save_index_daily_period(
            start_date='20250101', 
            end_date='20251001', 
            index_codes=test_codes,
            batch_size=10
        )
        
        if not result_df.empty:
            print(f"âœ… åŒºé—´æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(result_df)} æ¡è®°å½•")
        else:
            print("âš ï¸  åŒºé—´æ•°æ®è·å–å¤±è´¥æˆ–æ²¡æœ‰æ•°æ®")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()